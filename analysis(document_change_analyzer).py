# -*- coding: utf-8 -*-
"""analysis(document-change-analyzer).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rziKFXgWRn-59VHtIM6Du_Ta3wL71FGE
"""

# Semantic Document Change Analyzer

!pip install transformers

"""**Reading the documents into Python**"""

# Read policy version 1
with open("/Policy_v1.txt", "r", encoding="latin-1") as f:
    policy_v1 = f.read()

# Read policy version 2
with open("/Policy_v2.txt", "r", encoding="latin-1") as f:
    policy_v2 = f.read()

# Quick check
print("Policy V1 length:", len(policy_v1))
print("Policy V2 length:", len(policy_v2))

from transformers import AutoTokenizer, AutoModel
import torch

model_name = "sentence-transformers/all-MiniLM-L6-v2"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

print("Model loaded successfully")

"""**This function converts any document into a numeric form the computer can compare.**"""

def get_embedding(text):
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True
    )

    with torch.no_grad():
        outputs = model(**inputs)

    # Take the average of token embeddings
    embedding = outputs.last_hidden_state.mean(dim=1)
    return embedding

"""**Create embeddings for both documents**"""

# Create embeddings for both policy documents
embedding_v1 = get_embedding(policy_v1)
embedding_v2 = get_embedding(policy_v2)

# Quick check
print("Embedding V1 shape:", embedding_v1.shape)
print("Embedding V2 shape:", embedding_v2.shape)

"""**Now both documents are converted into numbers and are ready to be compared.**

**Compare the two documents**
"""

from torch.nn.functional import cosine_similarity

# Compare the two document embeddings
similarity_score = cosine_similarity(embedding_v1, embedding_v2)

print("Similarity score:", similarity_score.item())

"""**Split documents into sections**"""

import re

def split_into_sections(text):
    # Split based on numbered sections like "1. ", "2. ", etc.
    sections = re.split(r"\n\d+\.\s", text)

    # Clean and remove empty parts
    sections = [s.strip() for s in sections if s.strip()]
    return sections

"""**TESTing So that We can now compare section by section, instead of guessing from the whole document.**"""

sections_v1 = split_into_sections(policy_v1)
sections_v2 = split_into_sections(policy_v2)

print("Sections in Policy V1:", len(sections_v1))
print("Sections in Policy V2:", len(sections_v2))

"""**Comparing sections and finding major changes**"""

def compare_sections(sections_v1, sections_v2, threshold=0.85):
    major_changes = []

    for i in range(min(len(sections_v1), len(sections_v2))):
        emb1 = get_embedding(sections_v1[i])
        emb2 = get_embedding(sections_v2[i])

        score = cosine_similarity(emb1, emb2).item()

        if score < threshold:
            major_changes.append({
                "section_number": i + 1,
                "similarity_score": round(score, 2),
                "summary": sections_v2[i][:120] + "..."
            })

    return major_changes

major_changes = compare_sections(sections_v1, sections_v2)

for change in major_changes:
    print(change)

"""**For clean Output**"""

def format_output(changes):
    return {
        "total_major_changes": len(changes),
        "changes": [
            {
                "section": change["section_number"],
                "summary": change["summary"]
            }
            for change in changes
        ]
    }

final_output = format_output(major_changes)
final_output

import json

with open("output.json", "w") as f:
    json.dump(final_output, f, indent=2)

print("Output saved to output.json")

!ls

"""**Bento ML**"""

!pip install bentoml

import bentoml
print(bentoml.__version__)

import bentoml
from typing import Dict, Any

@bentoml.service(name="document_change_analyzer")
class DocumentChangeService:

    @bentoml.api
    def analyze(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        text_v1 = input_data["policy_v1"]
        text_v2 = input_data["policy_v2"]

        sections_v1 = split_into_sections(text_v1)
        sections_v2 = split_into_sections(text_v2)

        changes = compare_sections(sections_v1, sections_v2)
        result = format_output(changes)

        return result

# Create a test input
test_input = {
    "policy_v1": policy_v1,
    "policy_v2": policy_v2
}

# Create service instance
service_instance = DocumentChangeService()

# Call the API method directly
response = service_instance.analyze(test_input)

response

# Commented out IPython magic to ensure Python compatibility.
# %%writefile service.py
# print("service file created")
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile service.py
# import bentoml
# 
# @bentoml.service(name="document_change_analyzer")
# class DocumentChangeService:
#     pass
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile service.py
# import bentoml
# 
# @bentoml.service(name="document_change_analyzer")
# class DocumentChangeService:
# 
#     @bentoml.api
#     def health(self) -> dict:
#         return {"status": "ok"}
#

!bentoml serve service:DocumentChangeService

# Commented out IPython magic to ensure Python compatibility.
# %%writefile service.py
# import bentoml
# 
# @bentoml.service(name="document_change_analyzer")
# class DocumentChangeService:
# 
#     @bentoml.api
#     def analyze(self, payload: dict) -> dict:
#         doc_v1 = payload["doc_v1"]
#         doc_v2 = payload["doc_v2"]
# 
#         if doc_v1 == doc_v2:
#             return {
#                 "changed": False,
#                 "message": "No changes detected"
#             }
# 
#         return {
#             "changed": True,
#             "message": "Documents are different",
#             "length_v1": len(doc_v1),
#             "length_v2": len(doc_v2)
#         }

!bentoml serve service:DocumentChangeService

!bentoml serve service:DocumentChangeService &

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# bentoml serve service:DocumentChangeService &
# sleep 5
# 
# curl -X POST http://localhost:3000/analyze \
#   -H "Content-Type: application/json" \
#   -d '{"doc_v1": "Company policy allows remote work.", "doc_v2": "Company policy does not allow remote work."}'
#

"""**BentoML integration completed successfully.**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile service.py
# import bentoml
# from sentence_transformers import SentenceTransformer
# from sklearn.metrics.pairwise import cosine_similarity
# import numpy as np
# 
# # Load the embedding model ONCE
# model = SentenceTransformer("all-MiniLM-L6-v2")
# 
# @bentoml.service(name="document_change_analyzer")
# class DocumentChangeService:
# 
#     @bentoml.api
#     def analyze(self, payload: dict) -> dict:
#         doc_v1 = payload["doc_v1"]
#         doc_v2 = payload["doc_v2"]
# 
#         # Generate embeddings
#         emb_v1 = model.encode([doc_v1])
#         emb_v2 = model.encode([doc_v2])
# 
#         # Compute cosine similarity
#         similarity = cosine_similarity(emb_v1, emb_v2)[0][0]
# 
#         # Simple decision rule
#         if similarity > 0.85:
#             change_type = "minor_or_no_change"
#         else:
#             change_type = "major_change"
# 
#         return {
#             "similarity_score": float(similarity),
#             "change_type": change_type
#         }
#

!bentoml serve service:DocumentChangeService

